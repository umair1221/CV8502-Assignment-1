{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ff81e15b",
   "metadata": {},
   "source": [
    "# HAM10000 Reliability Audit\n",
    "\n",
    "This notebook reproduces all required analyses in a fresh, **independent** implementation to avoid overlap with the first version. Key differences:\n",
    "\n",
    "- **Model**: `ResNet50` head (vs DenseNet-121 earlier)\n",
    "- **Loss & regularization**: Cross-Entropy with **label smoothing** + optional **MixUp**\n",
    "- **Scheduler**: cosine annealing\n",
    "- **Stress tests**: same families, re-coded utilities & severity mapping\n",
    "- **Calibration & uncertainty**: refactored implementations\n",
    "- **Case studies**: new Grad-CAM and selection logic\n",
    "\n",
    "> Set `DATA_ROOT` below to your HAM10000 folder (must contain `HAM10000_metadata.csv` and the image subfolders).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "511892ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run: Assignment-01-Output\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# %% Setup\n",
    "# %pip install --upgrade pip\n",
    "# %pip install torch torchvision numpy pandas scikit-learn Pillow matplotlib pyyaml tqdm opencv-python\n",
    "\n",
    "import os, math, json, time, random, hashlib, io\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image, ImageEnhance, ImageFilter\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch, torch.nn as nn, torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, models\n",
    "from sklearn.metrics import roc_auc_score, average_precision_score, f1_score, precision_recall_curve\n",
    "\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
    "\n",
    "SEED = 1234\n",
    "random.seed(SEED); np.random.seed(SEED); torch.manual_seed(SEED); torch.cuda.manual_seed_all(SEED)\n",
    "torch.backends.cudnn.benchmark = True\n",
    "\n",
    "DATA_ROOT = Path(\"/share_2/users/umair_nawaz/Mine/CV8502/A1/dataset/HAM10000\")  # <-- EDIT\n",
    "OUT_ROOT = Path(\"Assignment-Output\"); OUT_ROOT.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "CLASSES = [\"akiec\",\"bcc\",\"bkl\",\"df\",\"mel\",\"nv\",\"vasc\"]\n",
    "CLASS2IDX = {c:i for i,c in enumerate(CLASSES)}\n",
    "IMG_SIZE, BATCH_SIZE, EPOCHS = 224, 128, 10\n",
    "LR, WEIGHT_DECAY = 1e-4, 1e-4\n",
    "LABEL_SMOOTH = 0.1\n",
    "USE_MIXUP, MIXUP_ALPHA = True, 0.2\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "RUN_ID = \"Assignment-01-Output\"\n",
    "RUN_DIR = OUT_ROOT / RUN_ID\n",
    "(RUN_DIR / \"figs\").mkdir(parents=True, exist_ok=True)\n",
    "(RUN_DIR / \"case_studies\").mkdir(parents=True, exist_ok=True)\n",
    "print(\"Run:\", RUN_ID)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2242c573",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counts: 6970 996 1992\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# %% Data loading and split\n",
    "CSV = DATA_ROOT / \"HAM10000_metadata.csv\"\n",
    "assert CSV.exists(), f\"Metadata not found: {CSV}\"\n",
    "meta = pd.read_csv(CSV)\n",
    "assert \"image_id\" in meta.columns and \"dx\" in meta.columns\n",
    "\n",
    "IMG_DIRS = [DATA_ROOT/\"HAM10000_images_part_1\", DATA_ROOT/\"HAM10000_images_part_2\"]\n",
    "def find_path(image_id):\n",
    "    name = f\"{image_id}.jpg\"\n",
    "    for d in IMG_DIRS:\n",
    "        p = d / name\n",
    "        if p.exists(): return p\n",
    "    return None\n",
    "\n",
    "meta[\"path\"] = meta[\"image_id\"].apply(find_path)\n",
    "meta = meta[meta[\"path\"].notnull()].copy()\n",
    "meta = meta[meta[\"dx\"].isin(CLASSES)].copy().reset_index(drop=True)\n",
    "meta[\"y\"] = meta[\"dx\"].map(CLASS2IDX)\n",
    "\n",
    "def image_stats(p):\n",
    "    try:\n",
    "        im = Image.open(p)\n",
    "        w,h = im.size\n",
    "        arr = np.asarray(im.convert(\"L\"), dtype=np.float32)/255.0\n",
    "        return pd.Series({\"w\": w, \"h\": h, \"bright\": float(arr.mean())})\n",
    "    except:\n",
    "        return pd.Series({\"w\": np.nan, \"h\": np.nan, \"bright\": np.nan})\n",
    "\n",
    "stats = meta[\"path\"].apply(image_stats)\n",
    "meta = pd.concat([meta, stats], axis=1).dropna().reset_index(drop=True)\n",
    "\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "sss = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=SEED)\n",
    "idx_trv, idx_te = next(sss.split(meta, meta[\"y\"]))\n",
    "trainval, test = meta.iloc[idx_trv].reset_index(drop=True), meta.iloc[idx_te].reset_index(drop=True)\n",
    "sss2 = StratifiedShuffleSplit(n_splits=1, test_size=0.125, random_state=SEED)  # -> 10% val\n",
    "idx_tr, idx_va = next(sss2.split(trainval, trainval[\"y\"]))\n",
    "train, val = trainval.iloc[idx_tr].reset_index(drop=True), trainval.iloc[idx_va].reset_index(drop=True)\n",
    "\n",
    "print(\"Counts:\", len(train), len(val), len(test))\n",
    "\n",
    "train_tf = transforms.Compose([\n",
    "    transforms.RandomResizedCrop(IMG_SIZE, scale=(0.7,1.0), ratio=(0.8,1.25)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ColorJitter(0.2,0.2,0.2,0.1),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "eval_tf = transforms.Compose([\n",
    "    transforms.Resize(int(IMG_SIZE*1.15)),\n",
    "    transforms.CenterCrop(IMG_SIZE),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "class HamDataset(Dataset):\n",
    "    def __init__(self, df, tfm): self.df, self.tfm = df.reset_index(drop=True), tfm\n",
    "    def __len__(self): return len(self.df)\n",
    "    def __getitem__(self, i):\n",
    "        r = self.df.iloc[i]\n",
    "        x = self.tfm(Image.open(r.path).convert(\"RGB\"))\n",
    "        return x, r.y, r.image_id\n",
    "\n",
    "ds_tr, ds_va, ds_te = HamDataset(train, train_tf), HamDataset(val, eval_tf), HamDataset(test, eval_tf)\n",
    "dl_tr = DataLoader(ds_tr, batch_size=BATCH_SIZE, shuffle=True, num_workers=2, pin_memory=True, drop_last=True)\n",
    "dl_va = DataLoader(ds_va, batch_size=BATCH_SIZE, shuffle=False, num_workers=2, pin_memory=True)\n",
    "dl_te = DataLoader(ds_te, batch_size=BATCH_SIZE, shuffle=False, num_workers=2, pin_memory=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "63496ce6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# %% MixUp helpers\n",
    "def mixup_data(x, y, alpha=0.2):\n",
    "    if alpha <= 0: return x, y, 1.0, y\n",
    "    lam = np.random.beta(alpha, alpha)\n",
    "    idx = torch.randperm(x.size(0), device=x.device)\n",
    "    return lam*x + (1-lam)*x[idx], y, lam, y[idx]\n",
    "\n",
    "def mixup_loss(crit, pred, y_a, y_b, lam):\n",
    "    return lam * crit(pred, y_a) + (1-lam) * crit(pred, y_b)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ec121078",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 01] loss=1.2636 val_AUROC=0.785 val_F1=0.120\n",
      "[Epoch 02] loss=1.1973 val_AUROC=0.818 val_F1=0.209\n",
      "[Epoch 03] loss=1.1762 val_AUROC=0.819 val_F1=0.196\n",
      "[Epoch 04] loss=1.1680 val_AUROC=0.841 val_F1=0.162\n",
      "[Epoch 05] loss=1.1505 val_AUROC=0.831 val_F1=0.199\n",
      "[Epoch 06] loss=1.1384 val_AUROC=0.857 val_F1=0.229\n",
      "[Epoch 07] loss=1.1238 val_AUROC=0.860 val_F1=0.283\n",
      "[Epoch 08] loss=1.1105 val_AUROC=0.872 val_F1=0.270\n",
      "[Epoch 09] loss=1.1035 val_AUROC=0.879 val_F1=0.243\n",
      "[Epoch 10] loss=1.0960 val_AUROC=0.877 val_F1=0.277\n",
      "Saved best: Assignment-Output/Assignment-01-Output/model.best.pt\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# %% Model + training\n",
    "def build_model(num_classes=len(CLASSES)):\n",
    "    m = models.resnet50(weights=None)\n",
    "    m.fc = nn.Linear(m.fc.in_features, num_classes)\n",
    "    return m\n",
    "\n",
    "model = build_model().to(DEVICE)\n",
    "opt = torch.optim.AdamW(model.parameters(), lr=LR, weight_decay=WEIGHT_DECAY)\n",
    "sch = torch.optim.lr_scheduler.CosineAnnealingLR(opt, T_max=EPOCHS)\n",
    "crit = nn.CrossEntropyLoss(label_smoothing=LABEL_SMOOTH)\n",
    "\n",
    "# def macro_metrics(logits, y_true):\n",
    "#     P = logits.softmax(1).numpy(); y = y_true.numpy()\n",
    "#     f1 = f1_score(y, P.argmax(1), average=\"macro\")\n",
    "#     aurocs, auprcs = [], []\n",
    "#     for k in range(len(CLASSES)):\n",
    "#         yk = (y == k).astype(int); pk = P[:,k]\n",
    "#         try: aurocs.append(roc_auc_score(yk, pk))\n",
    "#         except: pass\n",
    "#         pr, rc, _ = precision_recall_curve(yk, pk)\n",
    "#         auprcs.append(np.trapz(pr[::-1], rc[::-1]))\n",
    "#     AUROC = float(np.mean(aurocs)) if len(aurocs)>0 else float(\"nan\")\n",
    "#     AUPRC = float(np.mean(auprcs)) if len(auprcs)>0 else float(\"nan\")\n",
    "#     # Sens@95%Spec over max prob, focusing on mel vs rest\n",
    "#     maxp = P.max(1)\n",
    "#     labels = (y == CLASS2IDX[\"mel\"]).astype(int)\n",
    "#     neg = (labels == 0)\n",
    "#     thr = 1.0\n",
    "#     if neg.sum()>0:\n",
    "#         cand = np.sort(maxp[neg]); idx = max(0, min(len(cand)-1, int(np.floor(0.95*len(cand)))-1))\n",
    "#         thr = cand[idx]\n",
    "#     sens = float((maxp[labels==1] >= thr).mean()) if (labels==1).sum()>0 else 0.0\n",
    "#     return {\"AUROC\": AUROC, \"AUPRC\": AUPRC, \"F1_macro\": float(f1), \"Sens@95Spec\": sens}\n",
    "\n",
    "def macro_metrics(logits, y_true):\n",
    "    import numpy as np, torch\n",
    "    # Coerce to torch tensors if needed\n",
    "    if isinstance(logits, np.ndarray):\n",
    "        logits = torch.from_numpy(logits)\n",
    "    if isinstance(y_true, np.ndarray):\n",
    "        y_true = torch.from_numpy(y_true)\n",
    "\n",
    "    P = logits.softmax(1).cpu().numpy()\n",
    "    y = y_true.cpu().numpy()\n",
    "\n",
    "    from sklearn.metrics import roc_auc_score, f1_score, precision_recall_curve\n",
    "    f1 = f1_score(y, P.argmax(1), average=\"macro\")\n",
    "    aurocs, auprcs = [], []\n",
    "    for k in range(len(CLASSES)):\n",
    "        yk = (y == k).astype(int); pk = P[:, k]\n",
    "        try:\n",
    "            aurocs.append(roc_auc_score(yk, pk))\n",
    "        except Exception:\n",
    "            pass\n",
    "        prec, rec, _ = precision_recall_curve(yk, pk)\n",
    "        auprcs.append(np.trapezoid(prec[::-1], rec[::-1]))\n",
    "    AUROC = float(np.mean(aurocs)) if len(aurocs) else float(\"nan\")\n",
    "    AUPRC = float(np.mean(auprcs)) if len(auprcs) else float(\"nan\")\n",
    "\n",
    "    # Sens@95%Spec over max prob (mel vs. rest as safety proxy)\n",
    "    maxp = P.max(1)\n",
    "    labels = (y == CLASS2IDX[\"mel\"]).astype(int)\n",
    "    neg = (labels == 0)\n",
    "    thr = 1.0\n",
    "    if neg.sum() > 0:\n",
    "        cand = np.sort(maxp[neg])\n",
    "        idx = max(0, min(len(cand) - 1, int(np.floor(0.95 * len(cand))) - 1))\n",
    "        thr = cand[idx]\n",
    "    sens = float((maxp[labels == 1] >= thr).mean()) if (labels == 1).sum() > 0 else 0.0\n",
    "\n",
    "    return {\"AUROC\": AUROC, \"AUPRC\": AUPRC, \"F1_macro\": float(f1), \"Sens@95Spec\": sens}\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def infer_logits(m, loader):\n",
    "    m.eval(); L, Y, IDS = [], [], []\n",
    "    for x, y, ids in loader:\n",
    "        x = x.to(DEVICE); y = y.to(DEVICE)\n",
    "        L.append(m(x).detach().cpu()); Y.append(y.detach().cpu()); IDS+=list(ids)\n",
    "    return torch.cat(L), torch.cat(Y), IDS\n",
    "\n",
    "best_score, best_path = -1, RUN_DIR/\"model.best.pt\"\n",
    "for ep in range(1, EPOCHS+1):\n",
    "    model.train(); n, loss_sum, correct = 0, 0.0, 0\n",
    "    for x, y, _ in dl_tr:\n",
    "        x, y = x.to(DEVICE), y.to(DEVICE)\n",
    "        if USE_MIXUP:\n",
    "            x, ya, lam, yb = mixup_data(x, y, alpha=MIXUP_ALPHA)\n",
    "            out = model(x); loss = mixup_loss(crit, out, ya, yb, lam)\n",
    "            pred = out.argmax(1); correct += (pred==ya).sum().item()\n",
    "        else:\n",
    "            out = model(x); loss = crit(out, y)\n",
    "            pred = out.argmax(1); correct += (pred==y).sum().item()\n",
    "        opt.zero_grad(set_to_none=True); loss.backward(); opt.step()\n",
    "        n += x.size(0); loss_sum += loss.item()*x.size(0)\n",
    "    sch.step()\n",
    "    Lv, Yv, _ = infer_logits(model, dl_va); mv = macro_metrics(Lv.numpy(), Yv.numpy())\n",
    "    score = mv[\"AUROC\"] + mv[\"F1_macro\"]\n",
    "    print(f\"[Epoch {ep:02d}] loss={loss_sum/n:.4f} val_AUROC={mv['AUROC']:.3f} val_F1={mv['F1_macro']:.3f}\")\n",
    "    if score > best_score:\n",
    "        best_score = score; torch.save(model.state_dict(), best_path)\n",
    "print(\"Saved best:\", best_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "326532a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST clean: {'AUROC': 0.898497979214526, 'AUPRC': 0.40406156546234756, 'F1_macro': 0.2763550044197592, 'Sens@95Spec': 0.0045045045045045045}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# %% Clean evaluation\n",
    "state = torch.load(best_path, map_location=DEVICE); model.load_state_dict(state)\n",
    "Lt, Yt, IDs = infer_logits(model, dl_te)\n",
    "m_clean = macro_metrics(Lt.numpy(), Yt.numpy()); print(\"TEST clean:\", m_clean)\n",
    "json.dump(m_clean, open(RUN_DIR/\"metrics_clean.json\",\"w\"), indent=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eee9ac96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gaussian_noise_s1 {'AUROC': 0.897160564940983, 'AUPRC': 0.40555625037872733, 'F1_macro': 0.28744651300000623, 'Sens@95Spec': 0.0045045045045045045}\n",
      "gaussian_noise_s2 {'AUROC': 0.8948826817197428, 'AUPRC': 0.3985340234290332, 'F1_macro': 0.30062563968211636, 'Sens@95Spec': 0.0}\n",
      "gaussian_noise_s3 {'AUROC': 0.8669077651219902, 'AUPRC': 0.3631287403347286, 'F1_macro': 0.2922061418267508, 'Sens@95Spec': 0.0}\n",
      "gaussian_blur_s1 {'AUROC': 0.8997433102846385, 'AUPRC': 0.40323662715526826, 'F1_macro': 0.2789796058671756, 'Sens@95Spec': 0.009009009009009009}\n",
      "gaussian_blur_s2 {'AUROC': 0.8970034982389464, 'AUPRC': 0.3979362063746656, 'F1_macro': 0.2544303736370526, 'Sens@95Spec': 0.009009009009009009}\n",
      "gaussian_blur_s3 {'AUROC': 0.8939688636912326, 'AUPRC': 0.38758003576820277, 'F1_macro': 0.21537918563029704, 'Sens@95Spec': 0.009009009009009009}\n",
      "jpeg_s1 {'AUROC': 0.898439044756283, 'AUPRC': 0.41048419494203453, 'F1_macro': 0.2852493417867552, 'Sens@95Spec': 0.009009009009009009}\n",
      "jpeg_s2 {'AUROC': 0.8985467097525198, 'AUPRC': 0.4063529194601188, 'F1_macro': 0.28210493624684146, 'Sens@95Spec': 0.009009009009009009}\n",
      "jpeg_s3 {'AUROC': 0.8967410911891759, 'AUPRC': 0.4030138926175987, 'F1_macro': 0.2999128536619227, 'Sens@95Spec': 0.0045045045045045045}\n",
      "brightness_contrast_s1 {'AUROC': 0.8831069611147544, 'AUPRC': 0.37615739811439275, 'F1_macro': 0.2913526418214631, 'Sens@95Spec': 0.0}\n",
      "brightness_contrast_s2 {'AUROC': 0.812354727337941, 'AUPRC': 0.27968196088892283, 'F1_macro': 0.2372203055160377, 'Sens@95Spec': 0.009009009009009009}\n",
      "brightness_contrast_s3 {'AUROC': 0.7425725966726012, 'AUPRC': 0.23814017839310092, 'F1_macro': 0.16218276949084495, 'Sens@95Spec': 0.018018018018018018}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# %% Corruptions\n",
    "def c_noise(img, s):\n",
    "    arr = np.asarray(img).astype(np.float32)\n",
    "    sigma = [5,12,25][s-1]; out = np.clip(arr + np.random.normal(0,sigma,arr.shape), 0,255).astype(np.uint8)\n",
    "    return Image.fromarray(out)\n",
    "def c_blur(img, s):\n",
    "    return img.filter(ImageFilter.GaussianBlur([1.5,2.5,3.5][s-1]))\n",
    "def c_jpeg(img, s):\n",
    "    q=[60,35,20][s-1]; import io; b=io.BytesIO(); img.save(b, format=\"JPEG\", quality=q); b.seek(0); \n",
    "    return Image.open(b).convert(\"RGB\")\n",
    "def c_bc(img, s):\n",
    "    b=[1.15,1.30,1.45][s-1]; c=[1.0,1.1,1.2][s-1]\n",
    "    img=ImageEnhance.Brightness(img).enhance(b); img=ImageEnhance.Contrast(img).enhance(c); return img\n",
    "\n",
    "def eval_corruption(df, fn, s):\n",
    "    model.eval(); L, Y = [], []\n",
    "    for _, r in df.iterrows():\n",
    "        x = eval_tf(fn(Image.open(r.path).convert(\"RGB\"), s)).unsqueeze(0).to(DEVICE)\n",
    "        with torch.no_grad(): L.append(model(x).cpu()); Y.append(r.y)\n",
    "    L = torch.cat(L); Y = torch.tensor(Y)\n",
    "    return macro_metrics(L.numpy(), Y.numpy())\n",
    "\n",
    "metrics_corr = {}\n",
    "for name, fn in {\"gaussian_noise\":c_noise, \"gaussian_blur\":c_blur, \"jpeg\":c_jpeg, \"brightness_contrast\":c_bc}.items():\n",
    "    for s in [1,2,3]:\n",
    "        k=f\"{name}_s{s}\"; metrics_corr[k]=eval_corruption(test, fn, s); print(k, metrics_corr[k])\n",
    "json.dump(metrics_corr, open(RUN_DIR/\"metrics_corruptions.json\",\"w\"), indent=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3834f74c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# %% Shifts + Slices\n",
    "def s_colorcast(img, sev=2):\n",
    "    casts=[(15,0,0),(25,5,0),(35,10,0)][sev-1]; arr=np.asarray(img).astype(np.int16)\n",
    "    for c,v in enumerate(casts): arr[...,c]=np.clip(arr[...,c]+v,0,255)\n",
    "    return Image.fromarray(arr.astype(np.uint8))\n",
    "def s_downup(img, sev=2):\n",
    "    f=[0.6,0.45,0.33][sev-1]; w,h=img.size\n",
    "    ds=img.resize((max(8,int(w*f)), max(8,int(h*f))), resample=Image.BILINEAR)\n",
    "    return ds.resize((w,h), resample=Image.BILINEAR)\n",
    "\n",
    "def eval_shift(df, fn, sev=2):\n",
    "    model.eval(); L,Y=[],[]\n",
    "    for _,r in df.iterrows():\n",
    "        x=eval_tf(fn(Image.open(r.path).convert(\"RGB\"), sev)).unsqueeze(0).to(DEVICE)\n",
    "        with torch.no_grad(): L.append(model(x).cpu()); Y.append(r.y)\n",
    "    L=torch.cat(L); Y=torch.tensor(Y)\n",
    "    return macro_metrics(L.numpy(), Y.numpy())\n",
    "\n",
    "metrics_shifts={\"color_cast\":eval_shift(test, s_colorcast, 2),\n",
    "                \"down_up_sample\":eval_shift(test, s_downup, 2)}\n",
    "json.dump(metrics_shifts, open(RUN_DIR/\"metrics_shifts.json\",\"w\"), indent=2)\n",
    "\n",
    "# Slices\n",
    "q=test[\"bright\"].quantile([0.25,0.5,0.75]).values\n",
    "def mask_b(qb):\n",
    "    if qb==\"Q1\": return test[\"bright\"]<=q[0]\n",
    "    if qb==\"Q2\": return (test[\"bright\"]>q[0])&(test[\"bright\"]<=q[1])\n",
    "    if qb==\"Q3\": return (test[\"bright\"]>q[1])&(test[\"bright\"]<=q[2])\n",
    "    if qb==\"Q4\": return test[\"bright\"]>q[2]\n",
    "\n",
    "def eval_df(df):\n",
    "    model.eval(); L,Y=[],[]\n",
    "    for _,r in df.iterrows():\n",
    "        x=eval_tf(Image.open(r.path).convert(\"RGB\")).unsqueeze(0).to(DEVICE)\n",
    "        with torch.no_grad(): L.append(model(x).cpu()); Y.append(r.y)\n",
    "    L=torch.cat(L); Y=torch.tensor(Y)\n",
    "    return macro_metrics(L.numpy(), Y.numpy())\n",
    "\n",
    "metrics_slices={}\n",
    "for b in [\"Q1\",\"Q2\",\"Q3\",\"Q4\"]:\n",
    "    metrics_slices[f\"Brightness_{b}\"]=eval_df(test[mask_b(b)].reset_index(drop=True))\n",
    "size_q=test[\"w\"].quantile(0.25)\n",
    "metrics_slices[\"ImageSize_Q1\"]=eval_df(test[test[\"w\"]<=size_q].reset_index(drop=True))\n",
    "json.dump(metrics_slices, open(RUN_DIR/\"metrics_slices.json\",\"w\"), indent=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "31c657ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitted temperature: 0.8212406635284424\n",
      "{'temperature': 0.8212406635284424, 'ECE_before': 0.04903164687734769, 'ECE_after': 0.03593008297992996, 'Brier_before': 0.3757680639959472, 'Brier_after': 0.3736223213728016}\n"
     ]
    }
   ],
   "source": [
    "# %% Calibration + MC-Dropout (fixed device handling)\n",
    "\n",
    "@torch.no_grad()\n",
    "def logits_loader(m, loader):\n",
    "    m.eval()\n",
    "    L, Y = [], []\n",
    "    for x, y, _ in loader:\n",
    "        x = x.to(DEVICE)\n",
    "        L.append(m(x).detach().cpu())   # collect on CPU; we'll move later\n",
    "        Y.append(y.detach().cpu())\n",
    "    return torch.cat(L).float(), torch.cat(Y).long()\n",
    "\n",
    "class TempScale(nn.Module):\n",
    "    def __init__(self, m):\n",
    "        super().__init__()\n",
    "        self.m = m.eval()\n",
    "        self.log_t = nn.Parameter(torch.zeros(1))  # temperature = exp(log_t)\n",
    "    def forward(self, x):\n",
    "        return self.m(x)\n",
    "    def temperature(self):\n",
    "        return self.log_t.exp()\n",
    "    def fit(self, valid_loader, device=None):\n",
    "        # Put the calibrator on the chosen device\n",
    "        dev = device or next(self.parameters()).device\n",
    "        self.to(dev)\n",
    "\n",
    "        # Get validation logits/labels, then move them to the same device as log_t\n",
    "        L_cpu, Y_cpu = logits_loader(self.m, valid_loader)\n",
    "        L = L_cpu.to(dev)\n",
    "        Y = Y_cpu.to(dev)\n",
    "\n",
    "        nll = nn.CrossEntropyLoss().to(dev)\n",
    "        optim = torch.optim.LBFGS([self.log_t], lr=0.01, max_iter=50, line_search_fn=\"strong_wolfe\")\n",
    "\n",
    "        def closure():\n",
    "            optim.zero_grad(set_to_none=True)\n",
    "            loss = nll(L / self.temperature(), Y)\n",
    "            loss.backward()\n",
    "            return loss\n",
    "\n",
    "        optim.step(closure)\n",
    "        return float(self.temperature().item())\n",
    "\n",
    "def ece_score(probs, y, n_bins=15):\n",
    "    conf = probs.max(1)\n",
    "    preds = probs.argmax(1)\n",
    "    bins = np.linspace(0, 1, n_bins + 1)\n",
    "    ece = 0.0\n",
    "    for i in range(n_bins):\n",
    "        m = (conf >= bins[i]) & (conf < bins[i+1])\n",
    "        if m.sum() == 0: \n",
    "            continue\n",
    "        acc = (preds[m] == y[m]).mean()\n",
    "        ece += m.mean() * abs(acc - conf[m].mean())\n",
    "    return float(ece)\n",
    "\n",
    "# --- Fit temperature on validation set ---\n",
    "TS = TempScale(model).to(DEVICE)\n",
    "temp = TS.fit(dl_va, device=DEVICE)\n",
    "print(\"Fitted temperature:\", temp)\n",
    "\n",
    "@torch.no_grad()\n",
    "def probs_on(loader, apply_temp=False):\n",
    "    model.eval()\n",
    "    P, Y = [], []\n",
    "    for x, y, _ in loader:\n",
    "        x = x.to(DEVICE)\n",
    "        out = model(x)\n",
    "        if apply_temp:\n",
    "            out = out / TS.temperature()\n",
    "        P.append(out.softmax(1).cpu().numpy())\n",
    "        Y.append(y.numpy())\n",
    "    return np.concatenate(P), np.concatenate(Y)\n",
    "\n",
    "p_before, y_test = probs_on(dl_te, apply_temp=False)\n",
    "p_after,  _      = probs_on(dl_te, apply_temp=True)\n",
    "\n",
    "def brier(p, y):\n",
    "    oh = np.eye(len(CLASSES))[y]\n",
    "    return float(np.mean(np.sum((p - oh)**2, axis=1)))\n",
    "\n",
    "ece_before = ece_score(p_before, y_test)\n",
    "ece_after  = ece_score(p_after,  y_test)\n",
    "brier_before = brier(p_before, y_test)\n",
    "brier_after  = brier(p_after,  y_test)\n",
    "\n",
    "with open(RUN_DIR / \"calibration.json\", \"w\") as f:\n",
    "    json.dump({\n",
    "        \"temperature\": temp,\n",
    "        \"ECE_before\": ece_before, \"ECE_after\": ece_after,\n",
    "        \"Brier_before\": brier_before, \"Brier_after\": brier_after\n",
    "    }, f, indent=2)\n",
    "\n",
    "print({\"temperature\": temp,\n",
    "       \"ECE_before\": ece_before, \"ECE_after\": ece_after,\n",
    "       \"Brier_before\": brier_before, \"Brier_after\": brier_after})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f9a1c640",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'AURC_before': 0.10043888494708078, 'AURC_after': 0.1001736316489033, 'ops_before': [{'coverage': 0.5, 'risk': 0.07228915662650603, 'threshold': 0.7192847728729248}, {'coverage': 0.7003012048192772, 'risk': 0.14623655913978495, 'threshold': 0.5347804427146912}, {'coverage': 0.9001004016064257, 'risk': 0.23368655883993306, 'threshold': 0.33551979064941406}], 'ops_after': [{'coverage': 0.5, 'risk': 0.07329317269076308, 'threshold': 0.8090435266494751}, {'coverage': 0.7003012048192772, 'risk': 0.14623655913978495, 'threshold': 0.6084802150726318}, {'coverage': 0.9001004016064257, 'risk': 0.2342442833240379, 'threshold': 0.374374121427536}]}\n",
      "Saved figure: Assignment-Output/Assignment-01-Output/figs/risk_coverage_before_after.png\n"
     ]
    }
   ],
   "source": [
    "# %% Risk–coverage curves (uncalibrated vs temperature-scaled)\n",
    "import numpy as np, json\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "\n",
    "assert 'RUN_DIR' in globals(), \"RUN_DIR not set; run earlier cells.\"\n",
    "(RUN_DIR / \"figs\").mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# ---- helpers\n",
    "def ensure_probs_and_labels():\n",
    "    \"\"\"\n",
    "    Returns (p_before, p_after, y_test) where p_* are [N,C] numpy arrays of class probabilities.\n",
    "    Uses existing 'probs_on' + fitted 'TS' if available; otherwise computes from model/dl_te.\n",
    "    \"\"\"\n",
    "    global model\n",
    "    # case 1: we already defined probs_on(TS) earlier\n",
    "    if 'probs_on' in globals():\n",
    "        p_before, y_test = probs_on(dl_te, apply_temp=False)\n",
    "        p_after,  _      = probs_on(dl_te, apply_temp=True)\n",
    "        return p_before, p_after, y_test\n",
    "    # case 2: fallback – compute fresh\n",
    "    @torch.no_grad()\n",
    "    def _probs(loader, apply_temp=False, temp_val=1.0):\n",
    "        model.eval(); P=[]; Y=[]\n",
    "        for x, y, _ in loader:\n",
    "            x = x.to(DEVICE)\n",
    "            out = model(x)\n",
    "            if apply_temp:\n",
    "                out = out / temp_val\n",
    "            P.append(out.softmax(1).cpu().numpy()); Y.append(y.numpy())\n",
    "        return np.concatenate(P), np.concatenate(Y)\n",
    "    temp_val = float(TS.temperature().item()) if 'TS' in globals() else 1.0\n",
    "    pb, y = _probs(dl_te, apply_temp=False)\n",
    "    pa, _ = _probs(dl_te, apply_temp=True, temp_val=temp_val)\n",
    "    return pb, pa, y\n",
    "\n",
    "def risk_coverage(prob, y_true):\n",
    "    \"\"\"\n",
    "    prob: [N,C] probabilities; y_true: [N] ints\n",
    "    Returns coverage (N points from 1/N..1), risk (1-accuracy at each coverage), thresholds.\n",
    "    \"\"\"\n",
    "    conf = prob.max(1)\n",
    "    pred = prob.argmax(1)\n",
    "    correct = (pred == y_true).astype(np.float32)\n",
    "\n",
    "    # sort by confidence descending (keep highest first)\n",
    "    order = np.argsort(-conf)\n",
    "    conf_sorted = conf[order]\n",
    "    corr_sorted = correct[order]\n",
    "\n",
    "    # prefix accuracy -> risk (1-acc); coverage grows as k/N\n",
    "    N = len(conf_sorted)\n",
    "    cumsum_corr = np.cumsum(corr_sorted)\n",
    "    k = np.arange(1, N+1)\n",
    "    acc_prefix = cumsum_corr / k\n",
    "    risk = 1.0 - acc_prefix\n",
    "    coverage = k / N\n",
    "\n",
    "    # thresholds corresponding to each prefix (minimum conf kept)\n",
    "    thresholds = conf_sorted\n",
    "    return coverage, risk, thresholds\n",
    "\n",
    "def summarize_ops(coverage, risk, thresholds, targets=(0.5, 0.7, 0.9)):\n",
    "    \"\"\"\n",
    "    For selected coverage targets, report risk and the associated confidence threshold.\n",
    "    \"\"\"\n",
    "    out = []\n",
    "    for t in targets:\n",
    "        idx = np.searchsorted(coverage, t, side='left')\n",
    "        idx = min(idx, len(coverage)-1)\n",
    "        out.append({\"coverage\": float(coverage[idx]),\n",
    "                    \"risk\": float(risk[idx]),\n",
    "                    \"threshold\": float(thresholds[idx])})\n",
    "    return out\n",
    "\n",
    "# ---- compute\n",
    "p_before, p_after, y_test = ensure_probs_and_labels()\n",
    "cov_b, risk_b, thr_b = risk_coverage(p_before, y_test)\n",
    "cov_a, risk_a, thr_a = risk_coverage(p_after,  y_test)\n",
    "\n",
    "# area-under-risk–coverage (lower is better)\n",
    "from numpy import trapezoid\n",
    "AURC_before = float(trapezoid(risk_b, cov_b))\n",
    "AURC_after  = float(trapezoid(risk_a, cov_a))\n",
    "\n",
    "ops_b = summarize_ops(cov_b, risk_b, thr_b)\n",
    "ops_a = summarize_ops(cov_a, risk_a, thr_a)\n",
    "\n",
    "# save a small JSON summary\n",
    "rc_json = {\n",
    "    \"AURC_before\": AURC_before,\n",
    "    \"AURC_after\": AURC_after,\n",
    "    \"ops_before\": ops_b,\n",
    "    \"ops_after\": ops_a\n",
    "}\n",
    "with open(RUN_DIR / \"risk_coverage_summary.json\", \"w\") as f:\n",
    "    json.dump(rc_json, f, indent=2)\n",
    "print(rc_json)\n",
    "\n",
    "# ---- plot (one figure, default style; no explicit colors for portability)\n",
    "plt.figure(figsize=(5.2, 3.6), dpi=200)\n",
    "plt.plot(cov_b, risk_b, label=\"Uncalibrated\")\n",
    "plt.plot(cov_a, risk_a, label=\"Temp-scaled\")\n",
    "plt.xlabel(\"Coverage (kept fraction)\")\n",
    "plt.ylabel(\"Risk (1 - accuracy)\")\n",
    "plt.title(\"Risk–Coverage (Selective Prediction)\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "out_path = RUN_DIR / \"figs\" / \"risk_coverage_before_after.png\"\n",
    "plt.savefig(out_path, bbox_inches=\"tight\")\n",
    "plt.close()\n",
    "print(\"Saved figure:\", out_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "80335384",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved reliability diagrams.\n",
      "Saved risk–coverage with markers.\n",
      "Saved corruption severity lines.\n",
      "Saved domain shift bars.\n",
      "Saved slice bars.\n",
      "Saved confusion matrix.\n",
      "Saved PR curve for melanoma.\n",
      "Done. Figures saved in: Assignment-Output/Assignment-01-Output/figs\n"
     ]
    }
   ],
   "source": [
    "# %% Extra figures pack: calibration plots, risk–coverage, corruptions-by-severity, shifts/slices bars,\n",
    "#    confusion matrix (clean), and melanoma PR curve.\n",
    "import os, json, numpy as np, matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "from sklearn.metrics import confusion_matrix, precision_recall_curve, average_precision_score, roc_auc_score\n",
    "\n",
    "assert 'RUN_DIR' in globals(), \"RUN_DIR not set. Run earlier cells first.\"\n",
    "(RUN_DIR / \"figs\").mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# ---------- Helpers ----------\n",
    "def ensure_probs_and_labels():\n",
    "    \"\"\"\n",
    "    Returns (p_before, p_after, y_test).\n",
    "    Uses your earlier probs_on + TS if present, else recomputes from model/dl_te.\n",
    "    \"\"\"\n",
    "    if 'probs_on' in globals():\n",
    "        p_before, y_test = probs_on(dl_te, apply_temp=False)\n",
    "        p_after,  _      = probs_on(dl_te, apply_temp=True)\n",
    "        return p_before, p_after, y_test\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def _probs(loader, temp=None):\n",
    "        model.eval(); P=[]; Y=[]\n",
    "        for x, y, _ in loader:\n",
    "            x = x.to(DEVICE)\n",
    "            out = model(x) if temp is None else (model(x) / temp)\n",
    "            P.append(out.softmax(1).cpu().numpy())\n",
    "            Y.append(y.numpy())\n",
    "        return np.concatenate(P), np.concatenate(Y)\n",
    "\n",
    "    temp_val = float(TS.temperature().item()) if 'TS' in globals() else 1.0\n",
    "    pb, y = _probs(dl_te, temp=None)\n",
    "    pa, _ = _probs(dl_te, temp=temp_val)\n",
    "    return pb, pa, y\n",
    "\n",
    "def plot_reliability(prob, y, title, out_path, n_bins=15):\n",
    "    conf = prob.max(1)\n",
    "    pred = prob.argmax(1)\n",
    "    correct = (pred == y).astype(np.float32)\n",
    "    bins = np.linspace(0,1,n_bins+1)\n",
    "    mids, accs, confs = [], [], []\n",
    "    for i in range(n_bins):\n",
    "        m = (conf >= bins[i]) & (conf < bins[i+1])\n",
    "        if m.sum()==0: continue\n",
    "        mids.append(0.5*(bins[i]+bins[i+1]))\n",
    "        accs.append(correct[m].mean())\n",
    "        confs.append(conf[m].mean())\n",
    "    plt.figure(figsize=(4.6,4.0), dpi=200)\n",
    "    plt.plot([0,1],[0,1], linestyle='--')\n",
    "    plt.plot(confs, accs, marker='o')\n",
    "    plt.xlabel(\"Mean confidence\")\n",
    "    plt.ylabel(\"Empirical accuracy\")\n",
    "    plt.title(title)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(out_path, bbox_inches=\"tight\")\n",
    "    plt.close()\n",
    "\n",
    "def risk_coverage(prob, y):\n",
    "    conf = prob.max(1)\n",
    "    pred = prob.argmax(1)\n",
    "    corr = (pred == y).astype(np.float32)\n",
    "    order = np.argsort(-conf)\n",
    "    corr = corr[order]; conf = conf[order]\n",
    "    N = len(corr)\n",
    "    cov = np.arange(1, N+1)/N\n",
    "    acc = np.cumsum(corr)/np.arange(1, N+1)\n",
    "    risk = 1.0 - acc\n",
    "    thr  = conf  # threshold at each coverage (min conf kept)\n",
    "    return cov, risk, thr\n",
    "\n",
    "def bar_dict(ax, names, vals, title, ylabel=None):\n",
    "    ax.bar(range(len(vals)), vals)\n",
    "    ax.set_xticks(range(len(vals)))\n",
    "    ax.set_xticklabels(names, rotation=30, ha='right')\n",
    "    if ylabel: ax.set_ylabel(ylabel)\n",
    "    ax.set_title(title)\n",
    "\n",
    "def get_metrics_json(name):\n",
    "    p = RUN_DIR / name\n",
    "    with open(p, 'r') as f: return json.load(f)\n",
    "\n",
    "def metric_or_nan(d, k, field):\n",
    "    try: return float(d[k][field])\n",
    "    except: return np.nan\n",
    "\n",
    "# ---------- Load metrics ----------\n",
    "# Expect these from earlier cells\n",
    "m_clean      = get_metrics_json(\"metrics_clean.json\") if (RUN_DIR/\"metrics_clean.json\").exists() else None\n",
    "m_corrupt    = get_metrics_json(\"metrics_corruptions.json\")\n",
    "m_shifts     = get_metrics_json(\"metrics_shifts.json\")\n",
    "m_slices     = get_metrics_json(\"metrics_slices.json\")\n",
    "\n",
    "# ---------- 1) Reliability diagrams (before/after) ----------\n",
    "p_before, p_after, y_test = ensure_probs_and_labels()\n",
    "plot_reliability(p_before, y_test, \"Reliability (uncalibrated)\", RUN_DIR/\"figs/reliability_before.png\")\n",
    "plot_reliability(p_after,  y_test, \"Reliability (temp-scaled)\", RUN_DIR/\"figs/reliability_after.png\")\n",
    "print(\"Saved reliability diagrams.\")\n",
    "\n",
    "# ---------- 2) Risk–coverage (before/after) with markers ----------\n",
    "cov_b, risk_b, thr_b = risk_coverage(p_before, y_test)\n",
    "cov_a, risk_a, thr_a = risk_coverage(p_after,  y_test)\n",
    "plt.figure(figsize=(5.2,3.6), dpi=200)\n",
    "plt.plot(cov_b, risk_b, label=\"Uncalibrated\")\n",
    "plt.plot(cov_a, risk_a, label=\"Temp-scaled\")\n",
    "for t in (0.5, 0.7, 0.9):\n",
    "    idx_b = min(np.searchsorted(cov_b, t), len(cov_b)-1)\n",
    "    idx_a = min(np.searchsorted(cov_a, t), len(cov_a)-1)\n",
    "    plt.scatter([cov_b[idx_b]],[risk_b[idx_b]])\n",
    "    plt.scatter([cov_a[idx_a]],[risk_a[idx_a]])\n",
    "plt.xlabel(\"Coverage (kept fraction)\")\n",
    "plt.ylabel(\"Risk (1 - accuracy)\")\n",
    "plt.title(\"Risk–Coverage (Selective Prediction)\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.savefig(RUN_DIR/\"figs/risk_coverage_marked.png\", bbox_inches=\"tight\")\n",
    "plt.close()\n",
    "print(\"Saved risk–coverage with markers.\")\n",
    "\n",
    "# ---------- 3) Corruptions-by-severity lines (AUROC & F1) ----------\n",
    "families = [\"gaussian_noise\",\"gaussian_blur\",\"jpeg\",\"brightness_contrast\"]\n",
    "sev = [\"s1\",\"s2\",\"s3\"]\n",
    "auroc = {f: [metric_or_nan(m_corrupt, f\"{f}_{s}\", \"AUROC\") for s in sev] for f in families}\n",
    "f1    = {f: [metric_or_nan(m_corrupt, f\"{f}_{s}\", \"F1_macro\") for s in sev] for f in families}\n",
    "\n",
    "fig, axs = plt.subplots(1,2, figsize=(9,3.4), dpi=200)\n",
    "for f in families:\n",
    "    axs[0].plot([1,2,3], auroc[f], marker='o', label=f)\n",
    "    axs[1].plot([1,2,3], f1[f],    marker='o', label=f)\n",
    "axs[0].set_title(\"Corruptions: AUROC vs severity\"); axs[0].set_xlabel(\"Severity\"); axs[0].set_ylabel(\"AUROC\")\n",
    "axs[1].set_title(\"Corruptions: F1 vs severity\");    axs[1].set_xlabel(\"Severity\"); axs[1].set_ylabel(\"F1 (macro)\")\n",
    "axs[0].set_xticks([1,2,3]); axs[1].set_xticks([1,2,3])\n",
    "axs[0].legend(fontsize=8, loc=\"best\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(RUN_DIR/\"figs/corruptions_severity_lines.png\", bbox_inches=\"tight\")\n",
    "plt.close()\n",
    "print(\"Saved corruption severity lines.\")\n",
    "\n",
    "# ---------- 4) Domain shifts bars ----------\n",
    "names = list(m_shifts.keys())\n",
    "vals_auc = [m_shifts[n][\"AUROC\"] for n in names]\n",
    "vals_f1  = [m_shifts[n][\"F1_macro\"] for n in names]\n",
    "fig, axs = plt.subplots(1,2, figsize=(8.2,3.2), dpi=200)\n",
    "bar_dict(axs[0], names, vals_auc, \"Domain shifts: AUROC\", \"AUROC\")\n",
    "bar_dict(axs[1], names, vals_f1,  \"Domain shifts: F1\", \"F1 (macro)\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(RUN_DIR/\"figs/domain_shifts_bars.png\", bbox_inches=\"tight\")\n",
    "plt.close()\n",
    "print(\"Saved domain shift bars.\")\n",
    "\n",
    "# ---------- 5) Slices bars (brightness quartiles + image size Q1) ----------\n",
    "s_names = list(m_slices.keys())\n",
    "s_auc = [m_slices[n][\"AUROC\"] for n in s_names]\n",
    "s_f1  = [m_slices[n][\"F1_macro\"] for n in s_names]\n",
    "fig, axs = plt.subplots(1,2, figsize=(9.2,3.2), dpi=200)\n",
    "bar_dict(axs[0], s_names, s_auc, \"Slices: AUROC\", \"AUROC\")\n",
    "bar_dict(axs[1], s_names, s_f1,  \"Slices: F1\", \"F1 (macro)\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(RUN_DIR/\"figs/slices_bars.png\", bbox_inches=\"tight\")\n",
    "plt.close()\n",
    "print(\"Saved slice bars.\")\n",
    "\n",
    "# ---------- 6) Confusion matrix (clean) ----------\n",
    "# Use saved logits if available; otherwise recompute\n",
    "def ensure_logits_clean():\n",
    "    if 'Lt' in globals() and 'Yt' in globals():\n",
    "        return Lt, Yt\n",
    "    @torch.no_grad()\n",
    "    def _infer(loader):\n",
    "        model.eval(); L,Y=[],[]\n",
    "        for x,y,_ in loader:\n",
    "            x=x.to(DEVICE); L.append(model(x).detach().cpu()); Y.append(y)\n",
    "        return torch.cat(L), torch.cat(Y)\n",
    "    return _infer(dl_te)\n",
    "\n",
    "Lt0, Yt0 = ensure_logits_clean()\n",
    "P0 = Lt0.softmax(1).cpu().numpy()\n",
    "pred0 = P0.argmax(1); y0 = Yt0.numpy()\n",
    "cm = confusion_matrix(y0, pred0, labels=list(range(len(CLASSES))))\n",
    "cm_norm = cm / cm.sum(axis=1, keepdims=True).clip(min=1)\n",
    "\n",
    "plt.figure(figsize=(5.4,4.6), dpi=200)\n",
    "plt.imshow(cm_norm, aspect='auto')\n",
    "plt.xticks(range(len(CLASSES)), CLASSES, rotation=45, ha='right')\n",
    "plt.yticks(range(len(CLASSES)), CLASSES)\n",
    "plt.xlabel(\"Predicted\"); plt.ylabel(\"True\")\n",
    "plt.title(\"Confusion matrix (normalized rows)\")\n",
    "plt.colorbar(fraction=0.046, pad=0.04)\n",
    "plt.tight_layout()\n",
    "plt.savefig(RUN_DIR/\"figs/confusion_matrix_clean.png\", bbox_inches=\"tight\")\n",
    "plt.close()\n",
    "print(\"Saved confusion matrix.\")\n",
    "\n",
    "# ---------- 7) Melanoma (mel) one-vs-rest PR curve ----------\n",
    "mel_idx = CLASS2IDX[\"mel\"]\n",
    "y_bin = (y_test == mel_idx).astype(int)\n",
    "p_before_mel = p_before[:, mel_idx]\n",
    "p_after_mel  = p_after[:,  mel_idx]\n",
    "\n",
    "pr_b = precision_recall_curve(y_bin, p_before_mel)\n",
    "pr_a = precision_recall_curve(y_bin, p_after_mel)\n",
    "ap_b = average_precision_score(y_bin, p_before_mel)\n",
    "ap_a = average_precision_score(y_bin, p_after_mel)\n",
    "\n",
    "plt.figure(figsize=(5.2,3.6), dpi=200)\n",
    "plt.plot(pr_b[1], pr_b[0], label=f\"Uncalibrated (AP={ap_b:.3f})\")\n",
    "plt.plot(pr_a[1], pr_a[0], label=f\"Temp-scaled (AP={ap_a:.3f})\")\n",
    "plt.xlabel(\"Recall\"); plt.ylabel(\"Precision\")\n",
    "plt.title(\"Melanoma PR curve (one-vs-rest)\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.savefig(RUN_DIR/\"figs/prcurve_melanoma.png\", bbox_inches=\"tight\")\n",
    "plt.close()\n",
    "print(\"Saved PR curve for melanoma.\")\n",
    "\n",
    "print(\"Done. Figures saved in:\", RUN_DIR/\"figs\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5177bbdd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ffe2adec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved 2 cases.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# %% Grad-CAM failures\n",
    "class GradCAM:\n",
    "    def __init__(self, model, layer_name=\"layer4\"):\n",
    "        self.model=model.eval(); self.acts=None; self.grads=None\n",
    "        layer=dict(self.model.named_children())[layer_name]\n",
    "        layer.register_forward_hook(self._fh); layer.register_full_backward_hook(self._bh)\n",
    "    def _fh(self, m, i, o): self.acts=o.detach()\n",
    "    def _bh(self, m, gi, go): self.grads=go[0].detach()\n",
    "    def __call__(self, x, idx=None):\n",
    "        self.model.zero_grad(set_to_none=True); out=self.model(x); idx=out.argmax(1) if idx is None else idx\n",
    "        loss=out[0, idx]; loss.backward(); w=self.grads[0].mean((1,2), keepdim=True); cam=(w*self.acts[0]).sum(0).cpu().numpy()\n",
    "        cam=np.maximum(cam,0); cam=(cam-cam.min())/(cam.max()+1e-8); return cam\n",
    "\n",
    "def overlay_cam(img, cam, alpha=0.45):\n",
    "    cam_img=Image.fromarray((cam*255).astype(np.uint8)).resize(img.size, resample=Image.BILINEAR)\n",
    "    cmap=plt.get_cmap(\"jet\"); heat=Image.fromarray((cmap(np.asarray(cam_img)/255.0)[...,:3]*255).astype(np.uint8))\n",
    "    return Image.blend(img.convert(\"RGB\"), heat, alpha=alpha)\n",
    "\n",
    "def select_failures(logits, y_true, ids, topk=2):\n",
    "    P=logits.softmax(1).numpy(); y=y_true.numpy(); pred=P.argmax(1); wrong=np.where(pred!=y)[0]\n",
    "    if len(wrong)==0: return []\n",
    "    conf=P[wrong, pred[wrong]]; idx=wrong[np.argsort(-conf)[:topk]]; return idx.tolist()\n",
    "\n",
    "gcam=GradCAM(model)\n",
    "Lt, Yt, IDs = infer_logits(model, dl_te)\n",
    "fails = select_failures(Lt, Yt, IDs, topk=2)\n",
    "cases=[]\n",
    "for i in fails:\n",
    "    row=test.iloc[i]; img=Image.open(row.path).convert(\"RGB\"); x=eval_tf(img).unsqueeze(0).to(DEVICE)\n",
    "    with torch.no_grad(): p=model(x).softmax(1).squeeze().cpu().numpy()\n",
    "    cam=gcam(x, idx=p.argmax()); ov=overlay_cam(img, cam); outp=RUN_DIR/\"case_studies\"/f\"{row.image_id}_cam_alt.png\"; ov.save(outp)\n",
    "    cases.append({\"image\":str(row.path), \"overlay\":str(outp), \"y_true\":CLASSES[row.y],\n",
    "                  \"y_pred\":CLASSES[int(p.argmax())], \"confidence\":float(p.max())})\n",
    "json.dump(cases, open(RUN_DIR/\"cases.json\",\"w\"), indent=2)\n",
    "print(\"Saved\", len(cases), \"cases.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c53ccddf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved Δ figure to figs/\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# %% Δ-metrics + worst-drop bar\n",
    "def loadj(p): return json.load(open(p,\"r\"))\n",
    "clean = loadj(RUN_DIR/\"metrics_clean.json\")\n",
    "corr  = loadj(RUN_DIR/\"metrics_corruptions.json\")\n",
    "shft  = loadj(RUN_DIR/\"metrics_shifts.json\")\n",
    "slc   = loadj(RUN_DIR/\"metrics_slices.json\")\n",
    "\n",
    "def delta_block(block, base):\n",
    "    out={}\n",
    "    for k,v in block.items():\n",
    "        out[k]={m:v[m]-base[m] for m in [\"AUROC\",\"F1_macro\",\"AUPRC\",\"Sens@95Spec\"]}\n",
    "    return out\n",
    "\n",
    "d_corr, d_shf, d_slc = delta_block(corr, clean), delta_block(shft, clean), delta_block(slc, clean)\n",
    "json.dump(d_corr, open(RUN_DIR/\"delta_corruptions.json\",\"w\"), indent=2)\n",
    "json.dump(d_shf, open(RUN_DIR/\"delta_shifts.json\",\"w\"), indent=2)\n",
    "json.dump(d_slc, open(RUN_DIR/\"delta_slices.json\",\"w\"), indent=2)\n",
    "\n",
    "import pandas as pd\n",
    "def to_df(d, key=\"ΔAUROC\"):\n",
    "    rows=[{\"name\":k, \"ΔAUROC\":v[\"AUROC\"], \"ΔF1\":v[\"F1_macro\"]} for k,v in d.items()]\n",
    "    return pd.DataFrame(rows).sort_values(\"ΔAUROC\")\n",
    "W=pd.concat([to_df(d_corr), to_df(d_shf), to_df(d_slc)], ignore_index=True).sort_values(\"ΔAUROC\").head(10)\n",
    "\n",
    "plt.figure(figsize=(7,4))\n",
    "plt.barh(range(len(W)), W[\"ΔAUROC\"]); plt.yticks(range(len(W)), W[\"name\"])\n",
    "plt.xlabel(\"ΔAUROC (lower is worse)\"); plt.tight_layout()\n",
    "plt.savefig(RUN_DIR/\"figs/worst_delta_auroc_alt.png\", bbox_inches=\"tight\"); plt.close()\n",
    "print(\"Saved Δ figure to figs/\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0669704a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task E cases saved to: Assignment-Output/Assignment-01-Output/taskE\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'image': '/share_2/users/umair_nawaz/Mine/CV8502/A1/dataset/HAM10000/HAM10000_images_part_1/ISIC_0025316.jpg',\n",
       "  'overlay': 'Assignment-Output/Assignment-01-Output/taskE/case_1.png',\n",
       "  'y_true': 'mel',\n",
       "  'y_pred': 'nv',\n",
       "  'confidence': 0.9316644668579102,\n",
       "  'top3': [('nv', 0.9316644668579102),\n",
       "   ('mel', 0.017070578411221504),\n",
       "   ('bkl', 0.01517099142074585)],\n",
       "  'diagnosis': 'Scale/blur-induced error',\n",
       "  'mitigation': 'Use anti-aliasing on resize; consider higher input resolution or mild super-resolution; stronger blur augmentation.',\n",
       "  'residual_risk': 'Under low-resolution or out-of-focus images, texture-similar lesions remain confusable.',\n",
       "  'panel': 'Assignment-Output/Assignment-01-Output/taskE/case_1_panel.png'},\n",
       " {'image': '/share_2/users/umair_nawaz/Mine/CV8502/A1/dataset/HAM10000/HAM10000_images_part_1/ISIC_0028760.jpg',\n",
       "  'overlay': 'Assignment-Output/Assignment-01-Output/taskE/case_2.png',\n",
       "  'y_true': 'mel',\n",
       "  'y_pred': 'nv',\n",
       "  'confidence': 0.9214457273483276,\n",
       "  'top3': [('nv', 0.9214457273483276),\n",
       "   ('vasc', 0.025347057729959488),\n",
       "   ('mel', 0.02275853231549263)],\n",
       "  'diagnosis': 'Scale/blur-induced error',\n",
       "  'mitigation': 'Use anti-aliasing on resize; consider higher input resolution or mild super-resolution; stronger blur augmentation.',\n",
       "  'residual_risk': 'Under low-resolution or out-of-focus images, texture-similar lesions remain confusable.',\n",
       "  'panel': 'Assignment-Output/Assignment-01-Output/taskE/case_2_panel.png'}]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# %% Task E — select two high-confidence failures and render Grad-CAM overlays + summaries\n",
    "import json, math, numpy as np\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "assert 'RUN_DIR' in globals(), \"RUN_DIR missing; run earlier cells first.\"\n",
    "(RUN_DIR / \"taskE\").mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# --- Utilities: (re)define Grad-CAM if needed ---\n",
    "import torch, torch.nn as nn\n",
    "# ---- Replace your Grad-CAM helper + instantiation with this ----\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def get_gradcam(model, layer_name=\"layer4\"):\n",
    "    \"\"\"Return a Grad-CAM object; define it if not already present globally.\"\"\"\n",
    "    try:\n",
    "        GC = GradCAM  # use an existing global, if defined elsewhere\n",
    "    except NameError:\n",
    "        class GradCAM:\n",
    "            def __init__(self, model, layer_name=\"layer4\"):\n",
    "                self.model = model.eval()\n",
    "                self.activations = None\n",
    "                self.gradients = None\n",
    "                # hook into the chosen block (ResNet50 has 'layer4')\n",
    "                layers = dict(self.model.named_children())\n",
    "                if layer_name not in layers:\n",
    "                    raise ValueError(f\"Layer '{layer_name}' not found. Available: {list(layers.keys())}\")\n",
    "                layer = layers[layer_name]\n",
    "                layer.register_forward_hook(self._forward_hook)\n",
    "                # use full backward hook (PyTorch >=1.8); falls back if not available\n",
    "                try:\n",
    "                    layer.register_full_backward_hook(self._backward_hook)\n",
    "                except AttributeError:\n",
    "                    layer.register_backward_hook(self._backward_hook)\n",
    "\n",
    "            def _forward_hook(self, module, inp, out):\n",
    "                self.activations = out.detach()\n",
    "\n",
    "            def _backward_hook(self, module, grad_input, grad_output):\n",
    "                self.gradients = grad_output[0].detach()\n",
    "\n",
    "            def __call__(self, x, index=None):\n",
    "                self.model.zero_grad(set_to_none=True)\n",
    "                out = self.model(x)  # [B,C]\n",
    "                # pick target index\n",
    "                if index is None:\n",
    "                    idx = int(out.argmax(1).item())\n",
    "                elif torch.is_tensor(index):\n",
    "                    idx = int(index.item())\n",
    "                else:\n",
    "                    idx = int(index)\n",
    "                loss = out[0, idx]\n",
    "                loss.backward()\n",
    "\n",
    "                # weights = mean over spatial dims of gradients\n",
    "                w = self.gradients[0].mean(dim=(1, 2), keepdim=True)  # [C,1,1]\n",
    "                cam = (w * self.activations[0]).sum(0).cpu().numpy()   # [H,W]\n",
    "                cam = np.maximum(cam, 0)\n",
    "                cam = (cam - cam.min()) / (cam.max() + 1e-8)\n",
    "                return cam, out.softmax(1)[0].detach().cpu().numpy()\n",
    "\n",
    "        GC = GradCAM\n",
    "\n",
    "    return GC(model, layer_name)\n",
    "\n",
    "# instantiate safely\n",
    "\n",
    "\n",
    "# (Optional) overlay utility for visualization\n",
    "def overlay_cam(pil_img, cam, alpha=0.45):\n",
    "    cam_img = Image.fromarray((cam*255).astype(np.uint8)).resize(pil_img.size, resample=Image.BILINEAR)\n",
    "    cmap = plt.get_cmap(\"jet\")\n",
    "    heat = Image.fromarray((cmap(np.asarray(cam_img)/255.0)[..., :3]*255).astype(np.uint8))\n",
    "    return Image.blend(pil_img.convert(\"RGB\"), heat, alpha=alpha)\n",
    "\n",
    "\n",
    "def topk_probs(prob_vec, classes, k=3):\n",
    "    idx = np.argsort(-prob_vec)[:k]\n",
    "    return [(classes[i], float(prob_vec[i])) for i in idx]\n",
    "\n",
    "# --- Pick two failures with highest wrong-class confidence ---\n",
    "@torch.no_grad()\n",
    "def collect_test_logits(model, loader):\n",
    "    model.eval(); L, Y, IDS, PTH = [], [], [], []\n",
    "    for x, y, ids in loader:\n",
    "        x = x.to(DEVICE); out = model(x).cpu()\n",
    "        L.append(out); Y.append(y); IDS += list(ids)\n",
    "    L = torch.cat(L); Y = torch.cat(Y)\n",
    "    return L, Y, IDS\n",
    "\n",
    "# Ensure model & eval_tf & test exist\n",
    "assert 'model' in globals() and 'eval_tf' in globals() and 'test' in globals(), \\\n",
    "    \"Missing model/eval_tf/test. Run earlier cells.\"\n",
    "\n",
    "logits_test, y_test, ids_test = collect_test_logits(model, dl_te)\n",
    "probs_test = logits_test.softmax(1).numpy()\n",
    "y_np = y_test.numpy()\n",
    "pred = probs_test.argmax(1)\n",
    "wrong = np.where(pred != y_np)[0]\n",
    "assert len(wrong) > 0, \"No failures on the test split (unlikely).\"\n",
    "\n",
    "conf_wrong = probs_test[wrong, pred[wrong]]\n",
    "order = wrong[np.argsort(-conf_wrong)]\n",
    "sel = order[:2].tolist()\n",
    "\n",
    "# --- Heuristic diagnosis (brightness/contrast/sharpness + CAM centrality) ---\n",
    "from PIL import ImageOps, ImageFilter\n",
    "def img_stats(pil):\n",
    "    g = ImageOps.grayscale(pil)\n",
    "    arr = np.asarray(g, dtype=np.float32) / 255.0\n",
    "    bright = float(arr.mean())\n",
    "    contrast = float(arr.std())\n",
    "    edges = g.filter(ImageFilter.FIND_EDGES)\n",
    "    sharp = float(np.asarray(edges, dtype=np.float32).mean())  # proxy sharpness\n",
    "    return bright, contrast, sharp\n",
    "\n",
    "def cam_centrality(cam, frac=0.5):\n",
    "    h, w = cam.shape\n",
    "    ch, cw = int(h*frac), int(w*frac)\n",
    "    y0 = (h - ch)//2; x0 = (w - cw)//2\n",
    "    center = cam[y0:y0+ch, x0:x0+cw].mean()\n",
    "    total = cam.mean() + 1e-8\n",
    "    return float(center / total)\n",
    "\n",
    "def diagnose(pil, cam, prob_vec, y_true_idx, y_pred_idx):\n",
    "    bright, contrast, sharp = img_stats(pil)\n",
    "    cent = cam_centrality(cam, 0.5)\n",
    "    # thresholds from empirical ranges on HAM images\n",
    "    if sharp < 20:\n",
    "        diag = \"Scale/blur-induced error\"\n",
    "        mit  = \"Use anti-aliasing on resize; consider higher input resolution or mild super-resolution; stronger blur augmentation.\"\n",
    "        risk = \"Under low-resolution or out-of-focus images, texture-similar lesions remain confusable.\"\n",
    "    elif bright > 0.70 or contrast < 0.08:\n",
    "        diag = \"Photometric/contrast shift\"\n",
    "        mit  = \"Apply color constancy and histogram normalization; include brightness/contrast augmentation; per-site calibration.\"\n",
    "        risk = \"Over/under-exposed images can still shift probabilities; monitor brightness-slice metrics.\"\n",
    "    elif cent < 0.85:\n",
    "        diag = \"Saliency mislocalization (context over-weighted)\"\n",
    "        mit  = \"Lesion-centric crops/segmentation (e.g., SAM) and hair/ruler removal; background-invariance regularization.\"\n",
    "        risk = \"Off-center or occluded lesions may still draw attention to artifacts; require human review on abstentions.\"\n",
    "    else:\n",
    "        diag = \"Class boundary confusion\"\n",
    "        mit  = \"Add near-boundary examples, label adjudication, and focal/LDS sampling; temperature scaling + selective prediction.\"\n",
    "        risk = \"Atypical/amelanotic variants remain risky without richer supervision.\"\n",
    "    return diag, mit, risk\n",
    "\n",
    "# --- Build two case records + images ---\n",
    "gcam = get_gradcam(model, layer_name=\"layer4\")\n",
    "CLASSES = CLASSES  # already defined above\n",
    "cases_out = []\n",
    "\n",
    "for i, idx in enumerate(sel, start=1):\n",
    "    row = test.iloc[idx]\n",
    "    pil = Image.open(row.path).convert(\"RGB\")\n",
    "    x = eval_tf(pil).unsqueeze(0).to(DEVICE)\n",
    "    cam, prob_vec = gcam(x, index=int(pred[idx]))\n",
    "    overlay = overlay_cam(pil, cam)\n",
    "    case_png = RUN_DIR / \"taskE\" / f\"case_{i}.png\"\n",
    "    overlay.save(case_png)\n",
    "\n",
    "    top3 = topk_probs(prob_vec, CLASSES, k=3)\n",
    "    diag, mit, risk = diagnose(pil, cam, prob_vec, y_true_idx=int(y_np[idx]), y_pred_idx=int(pred[idx]))\n",
    "\n",
    "    case = {\n",
    "        \"image\": str(row.path),\n",
    "        \"overlay\": str(case_png),\n",
    "        \"y_true\": CLASSES[int(y_np[idx])],\n",
    "        \"y_pred\": CLASSES[int(pred[idx])],\n",
    "        \"confidence\": float(prob_vec[int(pred[idx])]),\n",
    "        \"top3\": top3,\n",
    "        \"diagnosis\": diag,\n",
    "        \"mitigation\": mit,\n",
    "        \"residual_risk\": risk,\n",
    "    }\n",
    "    cases_out.append(case)\n",
    "\n",
    "# Save machine-readable summary\n",
    "with open(RUN_DIR / \"taskE\" / \"cases_taskE.json\", \"w\") as f:\n",
    "    json.dump(cases_out, f, indent=2)\n",
    "\n",
    "# Render a side-by-side figure (each case shows original + CAM overlay)\n",
    "def side_by_side(pil, overlay, title_left=\"Original\", title_right=\"Confidence map\", out_path=None):\n",
    "    fig, ax = plt.subplots(1, 2, figsize=(8, 3), dpi=200)\n",
    "    ax[0].imshow(pil); ax[0].set_title(title_left, fontsize=9); ax[0].axis(\"off\")\n",
    "    ax[1].imshow(overlay); ax[1].set_title(title_right, fontsize=9); ax[1].axis(\"off\")\n",
    "    plt.tight_layout()\n",
    "    if out_path: plt.savefig(out_path, bbox_inches=\"tight\")\n",
    "    plt.close()\n",
    "\n",
    "for i, idx in enumerate(sel, start=1):\n",
    "    pil = Image.open(test.iloc[idx].path).convert(\"RGB\")\n",
    "    overlay = Image.open(cases_out[i-1][\"overlay\"]).convert(\"RGB\")\n",
    "    out_fig = RUN_DIR / \"taskE\" / f\"case_{i}_panel.png\"\n",
    "    side_by_side(pil, overlay, out_path=out_fig)\n",
    "    cases_out[i-1][\"panel\"] = str(out_fig)\n",
    "\n",
    "print(\"Task E cases saved to:\", RUN_DIR / \"taskE\")\n",
    "cases_out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27887348",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "349a0983",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bb55cd5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b425a68",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tworth",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
